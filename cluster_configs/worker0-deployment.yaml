# Deployment configuration template for a slave node worker
# Must have Cluster IP that references it
# Must have read access to a persistentVolumeClaim
# Must Deploy one pod/container
apiVersion: apps/v1
kind: Deployment
metadata:
  name: worker0-deployment

spec:

  replicas: 1

  selector:
    matchLabels:
      slave: worker0

  template:
    metadata:
      labels:
        slave: worker0

    spec:

      # Persistent volumes to request
      volumes:
        - name: worker-storage
          persistentVolumeClaim:
            # Must match the metadata
            claimName: workerdb-persistent-volume-claim

      containers:
        # Name and source image of the container
        - name: worker0
          image: stmutasa/dtflow_test:v1

#          # Environment password for storage access
#          env:
#            - name: DBPASSWORD
#              valueFrom:
#                secretKeyRef:
#                  name: dbpassword
#                  key: DBPASSWORD

          # Ports to open up
          ports:
            - containerPort: 5000

          # Default commands
          command: ["python3"]
          args: ["Distributed2.py", "--ps_hosts=ps0-cluster-ip-service:5000", "--worker_hosts=worker0-cluster-ip-service:5001,worker1-cluster-ip-service:5002", "--job_name=worker", "--task_index=0"]

          # Mount the institutional pvc inside this container
          volumeMounts:

            # Name must match
            - name: worker-storage
            # Where inside the container this storage should be available
              mountPath: /data
